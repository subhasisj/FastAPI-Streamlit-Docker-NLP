{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3",
   "language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np \n",
    "import spacy \n",
    "from sentence_transformers import SentenceTransformer\n",
    "from tqdm import tqdm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "     v1                                                 v2 Unnamed: 2  \\\n",
       "0   ham  Go until jurong point, crazy.. Available only ...        NaN   \n",
       "1   ham                      Ok lar... Joking wif u oni...        NaN   \n",
       "2  spam  Free entry in 2 a wkly comp to win FA Cup fina...        NaN   \n",
       "3   ham  U dun say so early hor... U c already then say...        NaN   \n",
       "4   ham  Nah I don't think he goes to usf, he lives aro...        NaN   \n",
       "\n",
       "  Unnamed: 3 Unnamed: 4  \n",
       "0        NaN        NaN  \n",
       "1        NaN        NaN  \n",
       "2        NaN        NaN  \n",
       "3        NaN        NaN  \n",
       "4        NaN        NaN  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>v1</th>\n      <th>v2</th>\n      <th>Unnamed: 2</th>\n      <th>Unnamed: 3</th>\n      <th>Unnamed: 4</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>ham</td>\n      <td>Go until jurong point, crazy.. Available only ...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>ham</td>\n      <td>Ok lar... Joking wif u oni...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>spam</td>\n      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>ham</td>\n      <td>U dun say so early hor... U c already then say...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>ham</td>\n      <td>Nah I don't think he goes to usf, he lives aro...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 99
    }
   ],
   "source": [
    "df = pd.read_csv('../Data/spam.csv',encoding='latin-1')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.iloc[:,0:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "  label                                               text\n",
       "0   ham  Go until jurong point, crazy.. Available only ...\n",
       "1   ham                      Ok lar... Joking wif u oni...\n",
       "2  spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
       "3   ham  U dun say so early hor... U c already then say...\n",
       "4   ham  Nah I don't think he goes to usf, he lives aro..."
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>label</th>\n      <th>text</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>ham</td>\n      <td>Go until jurong point, crazy.. Available only ...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>ham</td>\n      <td>Ok lar... Joking wif u oni...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>spam</td>\n      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>ham</td>\n      <td>U dun say so early hor... U c already then say...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>ham</td>\n      <td>Nah I don't think he goes to usf, he lives aro...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 101
    }
   ],
   "source": [
    "df.columns = ['label','text']\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Processing with spaCy: 100%|██████████| 5572/5572 [00:29<00:00, 186.72it/s]\n"
     ]
    }
   ],
   "source": [
    "nlp = spacy.load('en_core_web_sm')\n",
    "tqdm.pandas(desc='Processing with spaCy')\n",
    "spacy_results = df['text'].progress_map(nlp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode with Sentence Transformers\n",
    "\n",
    "sentence_bert = SentenceTransformer('paraphrase-distilroberta-base-v1')\n",
    "# tqdm.pandas(desc='Applying sentence-bert')\n",
    "# vectors = df['text'].progress_map(model.encode)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "Pandas Apply:   0%|          | 0/5572 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "b7839732dc5f4e9f843f8325238729bc"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "CPU times: user 12min 25s, sys: 6.08 s, total: 12min 31s\nWall time: 2min 36s\n"
     ]
    }
   ],
   "source": [
    "import swifter\n",
    "\n",
    "%time vectors_swifter = df['text'].swifter.apply(sentence_bert.encode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "Pandas Apply:   0%|          | 0/5572 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "3ed475b895b34021b0a7f087117e9bac"
      }
     },
     "metadata": {}
    }
   ],
   "source": [
    "df['raw_spacy'] = spacy_results\n",
    "df['raw_pos'] = df['raw_spacy'].swifter.apply(lambda x: ' '.join([t.pos_ for t in x]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "  label                                               text  \\\n",
       "0   ham  Go until jurong point, crazy.. Available only ...   \n",
       "1   ham                      Ok lar... Joking wif u oni...   \n",
       "2  spam  Free entry in 2 a wkly comp to win FA Cup fina...   \n",
       "3   ham  U dun say so early hor... U c already then say...   \n",
       "4   ham  Nah I don't think he goes to usf, he lives aro...   \n",
       "\n",
       "                                           raw_spacy  \\\n",
       "0  (Go, until, jurong, point, ,, crazy, .., Avail...   \n",
       "1           (Ok, lar, ..., Joking, wif, u, oni, ...)   \n",
       "2  (Free, entry, in, 2, a, wkly, comp, to, win, F...   \n",
       "3  (U, dun, say, so, early, hor, ..., U, c, alrea...   \n",
       "4  (Nah, I, do, n't, think, he, goes, to, usf, ,,...   \n",
       "\n",
       "                                             raw_pos  \\\n",
       "0  VERB ADP ADJ NOUN PUNCT ADJ PUNCT ADJ ADV ADP ...   \n",
       "1            INTJ ADJ PUNCT NOUN VERB NOUN ADV PUNCT   \n",
       "2  ADJ NOUN ADP NUM DET ADJ NOUN PART VERB PROPN ...   \n",
       "3  NOUN NOUN VERB ADV ADJ NOUN PUNCT NOUN AUX ADV...   \n",
       "4  PROPN PRON AUX PART VERB PRON VERB ADP NOUN PU...   \n",
       "\n",
       "                                       sentence-bert  \n",
       "0  [0.076579936, -0.3930265, 0.27844715, 0.371942...  \n",
       "1  [0.022812596, 0.17678502, 0.12619068, -0.65074...  \n",
       "2  [0.15409197, 0.06857502, -0.13811308, -0.40663...  \n",
       "3  [0.09308915, -0.12710004, -0.033977684, -0.630...  \n",
       "4  [-0.036661543, 0.19233567, -0.27760535, 0.3999...  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>label</th>\n      <th>text</th>\n      <th>raw_spacy</th>\n      <th>raw_pos</th>\n      <th>sentence-bert</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>ham</td>\n      <td>Go until jurong point, crazy.. Available only ...</td>\n      <td>(Go, until, jurong, point, ,, crazy, .., Avail...</td>\n      <td>VERB ADP ADJ NOUN PUNCT ADJ PUNCT ADJ ADV ADP ...</td>\n      <td>[0.076579936, -0.3930265, 0.27844715, 0.371942...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>ham</td>\n      <td>Ok lar... Joking wif u oni...</td>\n      <td>(Ok, lar, ..., Joking, wif, u, oni, ...)</td>\n      <td>INTJ ADJ PUNCT NOUN VERB NOUN ADV PUNCT</td>\n      <td>[0.022812596, 0.17678502, 0.12619068, -0.65074...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>spam</td>\n      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n      <td>(Free, entry, in, 2, a, wkly, comp, to, win, F...</td>\n      <td>ADJ NOUN ADP NUM DET ADJ NOUN PART VERB PROPN ...</td>\n      <td>[0.15409197, 0.06857502, -0.13811308, -0.40663...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>ham</td>\n      <td>U dun say so early hor... U c already then say...</td>\n      <td>(U, dun, say, so, early, hor, ..., U, c, alrea...</td>\n      <td>NOUN NOUN VERB ADV ADJ NOUN PUNCT NOUN AUX ADV...</td>\n      <td>[0.09308915, -0.12710004, -0.033977684, -0.630...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>ham</td>\n      <td>Nah I don't think he goes to usf, he lives aro...</td>\n      <td>(Nah, I, do, n't, think, he, goes, to, usf, ,,...</td>\n      <td>PROPN PRON AUX PART VERB PRON VERB ADP NOUN PU...</td>\n      <td>[-0.036661543, 0.19233567, -0.27760535, 0.3999...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 106
    }
   ],
   "source": [
    "df['sentence-bert'] = vectors_swifter\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "Pandas Apply:   0%|          | 0/5572 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "799e80b9326b48ab839658a3d009e915"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "   label                                               text  \\\n",
       "0      0  Go until jurong point, crazy.. Available only ...   \n",
       "1      0                      Ok lar... Joking wif u oni...   \n",
       "2      1  Free entry in 2 a wkly comp to win FA Cup fina...   \n",
       "3      0  U dun say so early hor... U c already then say...   \n",
       "4      0  Nah I don't think he goes to usf, he lives aro...   \n",
       "\n",
       "                                           raw_spacy  \\\n",
       "0  (Go, until, jurong, point, ,, crazy, .., Avail...   \n",
       "1           (Ok, lar, ..., Joking, wif, u, oni, ...)   \n",
       "2  (Free, entry, in, 2, a, wkly, comp, to, win, F...   \n",
       "3  (U, dun, say, so, early, hor, ..., U, c, alrea...   \n",
       "4  (Nah, I, do, n't, think, he, goes, to, usf, ,,...   \n",
       "\n",
       "                                             raw_pos  \\\n",
       "0  VERB ADP ADJ NOUN PUNCT ADJ PUNCT ADJ ADV ADP ...   \n",
       "1            INTJ ADJ PUNCT NOUN VERB NOUN ADV PUNCT   \n",
       "2  ADJ NOUN ADP NUM DET ADJ NOUN PART VERB PROPN ...   \n",
       "3  NOUN NOUN VERB ADV ADJ NOUN PUNCT NOUN AUX ADV...   \n",
       "4  PROPN PRON AUX PART VERB PRON VERB ADP NOUN PU...   \n",
       "\n",
       "                                       sentence-bert  \n",
       "0  [0.076579936, -0.3930265, 0.27844715, 0.371942...  \n",
       "1  [0.022812596, 0.17678502, 0.12619068, -0.65074...  \n",
       "2  [0.15409197, 0.06857502, -0.13811308, -0.40663...  \n",
       "3  [0.09308915, -0.12710004, -0.033977684, -0.630...  \n",
       "4  [-0.036661543, 0.19233567, -0.27760535, 0.3999...  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>label</th>\n      <th>text</th>\n      <th>raw_spacy</th>\n      <th>raw_pos</th>\n      <th>sentence-bert</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>Go until jurong point, crazy.. Available only ...</td>\n      <td>(Go, until, jurong, point, ,, crazy, .., Avail...</td>\n      <td>VERB ADP ADJ NOUN PUNCT ADJ PUNCT ADJ ADV ADP ...</td>\n      <td>[0.076579936, -0.3930265, 0.27844715, 0.371942...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0</td>\n      <td>Ok lar... Joking wif u oni...</td>\n      <td>(Ok, lar, ..., Joking, wif, u, oni, ...)</td>\n      <td>INTJ ADJ PUNCT NOUN VERB NOUN ADV PUNCT</td>\n      <td>[0.022812596, 0.17678502, 0.12619068, -0.65074...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1</td>\n      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n      <td>(Free, entry, in, 2, a, wkly, comp, to, win, F...</td>\n      <td>ADJ NOUN ADP NUM DET ADJ NOUN PART VERB PROPN ...</td>\n      <td>[0.15409197, 0.06857502, -0.13811308, -0.40663...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0</td>\n      <td>U dun say so early hor... U c already then say...</td>\n      <td>(U, dun, say, so, early, hor, ..., U, c, alrea...</td>\n      <td>NOUN NOUN VERB ADV ADJ NOUN PUNCT NOUN AUX ADV...</td>\n      <td>[0.09308915, -0.12710004, -0.033977684, -0.630...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0</td>\n      <td>Nah I don't think he goes to usf, he lives aro...</td>\n      <td>(Nah, I, do, n't, think, he, goes, to, usf, ,,...</td>\n      <td>PROPN PRON AUX PART VERB PRON VERB ADP NOUN PU...</td>\n      <td>[-0.036661543, 0.19233567, -0.27760535, 0.3999...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 107
    }
   ],
   "source": [
    "df['label'] = df.label.swifter.apply(lambda x : 1 if x =='spam' else 0)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(columns=['raw_spacy'],inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from xgboost import XGBClassifier\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stack_embeddings(embeddings):\n",
    "    import numpy as np\n",
    "    return np.vstack(embeddings.values)\n",
    "\n",
    "ct = ColumnTransformer([\n",
    "    ('bag of ngrams', TfidfVectorizer(ngram_range=(1, 2), max_features=3000), 'text'),\n",
    "    ('bag of POS', CountVectorizer(ngram_range=(1, 2)), 'raw_pos'),\n",
    "    # Lambda functions cannot be pickled\n",
    "    ('sentence bert', FunctionTransformer(stack_embeddings), 'sentence-bert'),\n",
    "    # ('bag of NER types', CountVectorizer(ngram_range=(1, 2)), 'raw_ner'),\n",
    "    # ('ngrams before', TfidfVectorizer(ngram_range=(1, 2), max_features=3000), 'raw_before'),\n",
    "    # ('ngrams after', TfidfVectorizer(ngram_range=(1, 2), max_features=3000), 'raw_after')    \n",
    "],remainder='passthrough')\n",
    "\n",
    "# lm = LogisticRegression()\n",
    "xgb = XGBClassifier(random_state=0)\n",
    "\n",
    "# pipeline = Pipeline([('transformer', ct), ('classifier', lm)])\n",
    "pipeline = Pipeline([('transformer', ct), ('classifier', xgb)])\n",
    "\n",
    "\n",
    "y,X = train_df.pop('label'),train_df\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y, test_size=0.3, random_state=42,stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[15:13:14] WARNING: ../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "CPU times: user 53.3 s, sys: 354 ms, total: 53.7 s\n",
      "Wall time: 5.52 s\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "%time model = pipeline.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "              precision    recall  f1-score   support\n\n           0       0.99      1.00      0.99      1448\n           1       0.99      0.91      0.95       224\n\n    accuracy                           0.99      1672\n   macro avg       0.99      0.95      0.97      1672\nweighted avg       0.99      0.99      0.99      1672\n\n"
     ]
    }
   ],
   "source": [
    "print(metrics.classification_report(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import joblib\n",
    "# filename = 'model.sav'\n",
    "# joblib.dump(model, filename)\n",
    "import dill\n",
    "\n",
    "\n",
    "pkl_filename = \"../Models/model.pkl\"\n",
    "with open(pkl_filename, 'wb') as file:\n",
    "    dill.dump(model, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\u001b[0m\u001b[01;32mmodel.pkl\u001b[0m*\n"
     ]
    }
   ],
   "source": [
    "ls ../Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(pkl_filename,'rb') as file:\n",
    "    loaded_model = dill.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_inference_df(input_text):\n",
    "\n",
    "    model_input_dict = {}\n",
    "    input_row_list = []\n",
    "    \n",
    "\n",
    "    spacy_raw = nlp(input_text)\n",
    "    # pos_tags = [t.pos_ for t in spacy_raw]\n",
    "\n",
    "    model_input_dict['text'] = input_text\n",
    "    model_input_dict['raw_pos'] =  ' '.join([t.pos_ for t in spacy_raw])\n",
    "    model_input_dict['sentence-bert'] = sentence_bert.encode(input_text)\n",
    "\n",
    "    input_row_list.append(model_input_dict)\n",
    "\n",
    "    model_input_df = pd.DataFrame(input_row_list)\n",
    "    return model_input_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([1])"
      ]
     },
     "metadata": {},
     "execution_count": 298
    }
   ],
   "source": [
    "sample_text = 'Free entry in 2 a wkly comp to win FA Cup final tkts 21st May 2005. Text FA to 87121 to receive entry question(std txt rate)T&C\\'s'\n",
    "# make_inference_df(sample_text)\n",
    "loaded_model.predict(make_inference_df(sample_text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Nah I don't think he goes to usf, he lives around here though\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([1])"
      ]
     },
     "metadata": {},
     "execution_count": 299
    }
   ],
   "source": [
    "sample_text_2 = 'Nah I don\\'t think he goes to usf, he lives around here though'\n",
    "print(sample_text_2)\n",
    "loaded_model.predict(make_inference_df(sample_text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}